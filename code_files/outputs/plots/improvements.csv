model,logical_consistency,stepwise_correctness,hallucination_penalty,answer_correctness,overall_reward
GPT-2,0.019938999999999985,0.030285000000000006,-0.01999899999999996,0.020201999999999998,0.030111
TinyLlama-1.1B,0.06059999999999999,0.07110999999999995,-0.03970000000000001,0.040600000000000025,0.07966999999999996
StableLM-3B,0.05018300000000003,0.060319999999999985,0.0199,0.04958000000000001,0.06010900000000008
Phi-2,0.05980000000000002,0.08049999999999996,-0.03069999999999999,0.0802,0.07038000000000011
Flan-T5-Small,0.03970299999999999,0.040178999999999965,0.005491999999999997,0.02987999999999999,0.04726400000000003
OPT-1.3B,0.04830000000000001,0.07019999999999998,-0.0252,0.039600000000000024,0.07440000000000002
