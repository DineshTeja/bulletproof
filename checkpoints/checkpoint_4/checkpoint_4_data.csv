Model,LogicalConsistency_Before,LogicalConsistency_After,LogicalConsistency_AbsChange,LogicalConsistency_PctChange,StepwiseCorrectness_Before,StepwiseCorrectness_After,StepwiseCorrectness_AbsChange,StepwiseCorrectness_PctChange,HallucinationPenalty_Before,HallucinationPenalty_After,HallucinationPenalty_AbsChange,HallucinationPenalty_PctChange,AnswerCorrectness_Before,AnswerCorrectness_After,AnswerCorrectness_AbsChange,AnswerCorrectness_PctChange,OverallReward_Before,OverallReward_After,OverallReward_AbsChange,OverallReward_PctChange
Phi-2,0.478362,0.538145,0.059783,12.5,0.402178,0.482614,0.080436,20.0,0.153246,0.122597,-0.030649,-20.0,0.347891,0.428023,0.080132,23.0,0.621759,0.692148,0.070389,11.3
StableLM-3B,0.419783,0.469826,0.050043,11.9,0.352471,0.412733,0.060262,17.1,0.179842,0.199783,0.019941,11.1,0.296753,0.346278,0.049525,16.7,0.541283,0.601416,0.060133,11.1
TinyLlama-1.1B,0.321567,0.382149,0.060582,18.8,0.252783,0.323816,0.071033,28.0,0.198342,0.158673,-0.039669,-20.0,0.221935,0.262481,0.040546,18.2,0.387682,0.467384,0.079702,20.6
OPT-1.3B,0.317638,0.347429,0.029791,9.4,0.284728,0.335674,0.050946,17.9,0.202475,0.182193,-0.020282,-10.0,0.212378,0.242759,0.030381,14.3,0.373518,0.423774,0.050256,13.5
Flan-T5-Small,0.278256,0.317892,0.039636,14.2,0.221573,0.261897,0.040324,18.2,0.233461,0.212968,-0.020493,-8.8,0.188734,0.218579,0.029845,15.8,0.323562,0.373768,0.050206,15.5
GPT-2,0.263475,0.283642,0.020167,7.7,0.191896,0.222275,0.030379,15.8,0.251783,0.231714,-0.020069,-8.0,0.162457,0.182739,0.020282,12.5,0.311892,0.342037,0.030145,9.7